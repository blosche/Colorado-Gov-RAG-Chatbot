{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to service_questions.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load API key from environment variable\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(\n",
    "    api_key= api_key,\n",
    ")\n",
    "\n",
    "def make_valid_filename(name):\n",
    "    return \"\".join(c if c.isalnum() else \"_\" for c in name)\n",
    "\n",
    "# Function to read the CSV file and load the data\n",
    "def load_service_data(csv_path):\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "# Function to read the raw text from files\n",
    "def load_raw_texts(file_folder):\n",
    "    raw_texts = {}\n",
    "    for filename in os.listdir(file_folder):\n",
    "        if filename.endswith('.txt'):\n",
    "            service_name = make_valid_filename(filename.replace('.txt', ''))\n",
    "            with open(os.path.join(file_folder, filename), 'r', encoding='utf-8') as file:\n",
    "                raw_texts[service_name] = file.read()\n",
    "    return raw_texts\n",
    "\n",
    "# Function to truncate text to fit within token limits\n",
    "def truncate_text(text, max_tokens):\n",
    "    tokens = text.split()\n",
    "    if len(tokens) > max_tokens:\n",
    "        tokens = tokens[:max_tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Function to generate questions using OpenAI GPT API\n",
    "def generate_questions(main_text, raw_text):\n",
    "    max_tokens = 9000  # Adjust as necessary to stay well below the limit\n",
    "    truncated_main_text = truncate_text(main_text, max_tokens // 2)\n",
    "    truncated_raw_text = truncate_text(raw_text, max_tokens // 2)\n",
    "\n",
    "    prompt = (\n",
    "        f\"Based on the website text and the services described: '{truncated_main_text}', create 5 simple questions that users might ask about these services. \"\n",
    "        \"Ignore surrounding website details. \"\n",
    "        \"Questions should be in plain language and no more than 7 words long. \"\n",
    "        \"Each question must include terms related to the services, using the service name or related terms. \"\n",
    "        \"For example, if the service is 'Apply for Health First Colorado and Child Health Plan Plus', use terms like 'Health First Colorado', 'medical assistance', 'health benefits', or 'health coverage'. \"\n",
    "        \"Avoid vague questions like 'Where can I check my application status?'. \"\n",
    "        \"Revise the questions to ensure they are specific to the services provided.\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": truncated_raw_text},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Function to create the JSON output\n",
    "def create_json_output(service_data, raw_texts, output_path, num_services):\n",
    "    output = []\n",
    "    for idx, row in service_data.iterrows():\n",
    "        if idx >= num_services:\n",
    "            break\n",
    "\n",
    "        main_text = row['mainText']\n",
    "        main_url = row['mainURL']\n",
    "        dept_name = row['deptName']\n",
    "        dept_url = row['deptURL']\n",
    "        service_key = main_text.replace(' ', '_')\n",
    "\n",
    "        if service_key in raw_texts:\n",
    "            raw_text = raw_texts[service_key]\n",
    "            questions = generate_questions(main_text, raw_text)\n",
    "            output.append({\n",
    "                \"mainText\": main_text,\n",
    "                \"mainURL\": main_url,\n",
    "                \"deptName\": dept_name,\n",
    "                \"deptURL\": dept_url,\n",
    "                \"questions\": questions\n",
    "            })\n",
    "\n",
    "    with open(output_path, 'w') as outfile:\n",
    "        json.dump(output, outfile, indent=4)\n",
    "\n",
    "# Main function to orchestrate the process\n",
    "def main():\n",
    "    csv_path = 'colorado_services.csv'\n",
    "    file_folder = 'pages'\n",
    "    output_path = 'service_questions.json'\n",
    "    num_services = 1000\n",
    "\n",
    "    service_data = load_service_data(csv_path)\n",
    "    raw_texts = load_raw_texts(file_folder)\n",
    "    create_json_output(service_data, raw_texts, output_path, num_services)\n",
    "    print(f\"Output saved to {output_path}\")\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
